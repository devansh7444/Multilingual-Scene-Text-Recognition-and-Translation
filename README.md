# Multilingual Scene Text Recognition and Translation

## Using Hybrid OCR and Machine Translation Approach

## ğŸ“Œ Project Overview

This Project-Based Learning (PBL) initiative focuses on developing a **Multilingual Scene Text Recognition and Translation System** that uses a hybrid approach combining **Optical Character Recognition (OCR)** and **Machine Translation (MT)** techniques. The goal is to extract text from natural scene images across different languages and translate it into a user-defined target language using AI models.

The project addresses real-world challenges in **cross-language communication, accessibility**, and **global usability of visual content**.

## ğŸ¯ Objectives

- Detect and extract text from natural scene images using OCR.
- Identify the language of the recognized text.
- Translate extracted multilingual text to a user-defined target language.
- Evaluate system accuracy using standard metrics (BLEU, WER, etc.).
- Visualize and analyze OCR performance across languages and image types.

## ğŸ§  Technologies Used

- **Programming Language:** Python
- **Environment:** Jupyter Notebook
- **Core Libraries:**
  - `cv2` (OpenCV) â€“ Image processing
  - `pytesseract`, `easyocr` â€“ OCR engines
  - `langdetect`, `googletrans`, `nltk` â€“ Language detection and translation
  - `jiwer` â€“ WER calculation
  - `matplotlib`, `seaborn`, `wordcloud` â€“ Visualization
  - `scikit-learn` â€“ Evaluation and metrics

## ğŸ—‚ï¸ Project Structure

```bash
PBL_Project.ipynb         # Main notebook with code and outputs
README.md                 # Project documentation
requirements.txt          # Python dependencies
```

## ğŸ§© Key Features

- ğŸŒ **Multilingual OCR Support**: Scene text recognition in diverse scripts using both Tesseract and EasyOCR.
- ğŸˆ³ **Language Detection**: Automatic language identification of detected text.
- ğŸ” **Machine Translation**: Real-time translation using Google Translate API.
- ğŸ“Š **Evaluation Metrics**:
  - BLEU Score for translation accuracy
  - WER (Word Error Rate) for OCR reliability
- ğŸ“ˆ **Visual Feedback**: Heatmaps, word clouds, and confidence scores for model interpretability.

## ğŸ§ª Model Evaluation

The notebook includes training and evaluation of multiple models with performance metrics such as:

- Accuracy
- Precision
- Recall
- F1 Score
- Cross-Validation Results

Model outputs are visualized using confusion matrices, ROC curves, and performance graphs.

## ğŸ”¬ Experimental Workflow

- **Image Input**: Natural scene image with text (any language).
- **Preprocessing**: Image enhancement using OpenCV techniques.
- **OCR Engine**: Text extraction using pytesseract and EasyOCR.
- **Language Detection**: Detected using langdetect or custom NLP logic.
- **Translation**: Translated via Google Translate (API/client).
- **Evaluation**: Compared against ground truth using BLEU and WER.

## ğŸ”§ How to Run the Project

1. Clone the repository or download the `.ipynb` file.
2. Ensure you have Python 3.x and Jupyter installed.
3. Install dependencies:

```bash
pip install -r requirements.txt
```

4. Launch the notebook:

```bash
jupyter notebook PBL_Project.ipynb
```

5. Run all cells sequentially to explore data and model results.

> âš ï¸ **Note**: Tesseract OCR must be installed separately on your system:

```bash
sudo apt install tesseract-ocr
```

## âœ… Results Summary

- Successfully extracted and translated text from multilingual scene images.
- EasyOCR improved performance in low-light and non-Latin script scenarios.
- Google Translate provided accurate sentence-level translations.
- Evaluation metrics confirmed robustness of hybrid OCR + MT approach.

## ğŸ“Š Sample Outputs

- Detected text overlays on scene images.
- Word clouds of frequently detected terms.
- BLEU score comparisons between models.
- WER values for multiple languages.

## ğŸ‘¨â€ğŸ’» Authors & Contributors

- **Authors** â€“ Devanshu Sawarkar([GithubID](https://github.com/DevanshuSawarkar)), Pratham Agrawal([GithubID](https://github.com/PrathamAgrawal51)), Devansh Motghare([GithubID](https://github.com/devansh7444))
- **Institution**: Symbiosis Institute of Technology, Nagpur
- **Course**: B.Tech Computer Science

## ğŸ“ Mentors
- Dr. Latika Pinjarkar ([GithubID](https://github.com/latika2019))

## ğŸ“š Acknowledgments

- OpenCV and Tesseract teams for robust OCR tools.
- Google Translate API and EasyOCR for multilingual support.
- Faculty mentors for guidance and evaluation.

## ğŸ“Œ Future Work

- Integration with mobile/web camera feeds.
- Offline translation using transformer-based models (e.g., MarianMT, M2M100).
- End-to-end multilingual scene understanding with vision-language transformers.

## âš–ï¸ License

This project is for educational and academic purposes only.
